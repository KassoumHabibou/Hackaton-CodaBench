{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: High resolution prediction of flood maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this model is used to measure global performance the performance of the pipeline.\n",
    "\n",
    "**The last section of this notebook create a submission file for the challenge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import src.baseline_model02 as bm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "The next cell allows you to quickly test models by reducing the amount of data used.\n",
    "\n",
    "*nb_train_minicube*, *nb_test_minicube* and *nb_val_minicube*, are used to limit the number of \"mini data cube\" used in train/test/val sets and therefore reduce the computational cost of the training and hyper parameters exploration. With also only keep minicubes above the *min_score_model1* threshold.\n",
    "\n",
    "If you choose a high number of minicubes, the threshold should be low enough.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test = bm.BaseLineModel(\n",
    "    \"localdata/smallbox/label/label_\",\n",
    "    dynamic_features_path = \"localdata/Model1_score_ERA5_Rez_v2.nc\",\n",
    "    static_features_root_path = \"localdata/smallbox/static/static_\",\n",
    "    dynamic_features_FR_path = \"localdata/Model1_Score_Full_Rez_v2.nc\",\n",
    "    inf_dynamic_features_FR_path = \"localdata/Model1_Score_Full_Rez_inf.nc\",\n",
    "    static_features_FR_path = \"localdata/static_Full_Rez.nc\",\n",
    "    labels_ERA5_path = \"localdata/final_label_Full_ERA5.nc\",\n",
    "    labels_FR_path = \"localdata/final_label_Full_Rez.nc\",\n",
    "    nb_train_minicube = 80, #Those values are very small for good performance you will need more datacubes\n",
    "    nb_test_minicube = 80, #Those values are very small for apropriate test you will need more datacubes\n",
    "    nb_val_minicube = 20,\n",
    "    min_score_model1 = 0.2,\n",
    "    name=\"Baseline_Model_2_Small_20_02\",\n",
    "    seed=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of the train / test / val dataset\n",
    "\n",
    "When using a high number of minicubes or low threshold, this process can still be quite long. The vectorised train / test / val can be saved to gain time when training several models on the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Training a Random Forest with all features, 150 trees and depth 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.load_indiv([True, #soilgrid_bdod\n",
    "                                          True, #soilgrid_cfvo\n",
    "                                          True, #soilgrid_silt\n",
    "                                          True, #soilgrid_clay\n",
    "                                          True, #soilgrid_sand\n",
    "                                          True, #depth_to_bedrock\n",
    "                                          True, #altitude\n",
    "                                          True, #aspect\n",
    "                                          True, #slope\n",
    "                                          True, #water_density\n",
    "                                          True, #watershed\n",
    "                                          True, #topological_catchment_areas\n",
    "                                          True, #dist_sea\n",
    "                                          True, #dist_riv\n",
    "                                          True, #M1_score\n",
    "                                          150, \n",
    "                                          8], \n",
    "                                     False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading model\n",
    "\n",
    "Vectorised test/train/validation dataset and trainned models are saved (the Full test saved is saved independently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.save_to_disk()\n",
    "\n",
    "#if you want to load a previously trained model :\n",
    "# baseline_model_generator_test = baseline_model_generator_test.load_from_disk(\"Baseline_Model_2_Small_20_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters search\n",
    "\n",
    "Using Genetic Algorithms for hyper parameters optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_model_generator_test.GA_optimisation(ngen = 40, pop = 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis\n",
    "\n",
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.print_feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographical results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction score Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### False Positive, True Positive, False Negative Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.load_FullRez()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.print_TNTPFN(save_path=\"graph/Model2/TNTPFN/\", thresholdM1=0.5, thresholdM2=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.print_proba(save_path=\"graph/Model2/Proba/\", thresholdM1=0.5, thresholdM2=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing of the full test data\n",
    "\n",
    "Loading of the Full Test Dataset from disk. To compute the performance of the model, we need to flaten it.\n",
    "\n",
    "The flaten Full test (all France data on the define time slices) might be quite long to process.\n",
    "Furthermore the *Full test set*, by nature, is fixed, so we process the flaten *Full Test Set* independently.\n",
    "\n",
    "When you have done this process one time, you don't need to do it again as long as you don't change your first model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.prepare_data(compute_full_test_set=True) #This will take a while, only do it one time\n",
    "baseline_model_generator_test.save_full_test_to_disk(name=\"Full\") #Saving the results to disk\n",
    "baseline_model_generator_test.load_full_test_from_disk(name=\"Full\") #Loading the results from disk, start from here if you already computed the full test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing of the full test data\n",
    "\n",
    "Loading of the Full Test Dataset from disk.\n",
    "The vectorised Full train test (all France data on the define time slices for test train might be quite long to process).\n",
    "Furthermore the *Full test set*, by nature, is fixed, so we process the vectorised *Full Test Set* independently.\n",
    "When you have done this process one time you don't need to do it again as long as you don't change your first model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.prepare_data(compute_full_test_set=True) #This will take a while, only do it one time\n",
    "baseline_model_generator_test.save_full_test_to_disk(name=\"Full\") #Saving the results to disk\n",
    "baseline_model_generator_test.load_full_test_from_disk(name=\"Full\") #Loading the results from disk, start from here if you already computed the full test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.auc_graph(\"Full_Test\", \"\", [0.01,0.05,0.1,0.15, 0.2,0.3, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.process_AUC_metrics(filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.process_prediction_metrics(filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation of predictions for codabench\n",
    "\n",
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.load_InfRez()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing of the prediction map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.print_proba_inf(save_path=\"graph/Model2/inference/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_generator_test.save_full_pred()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of the previously computed predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_geo_env_dav_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
